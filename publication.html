<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tao Wang - List of Publications</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tao Wang - List of Publications</name>
              </p>
              <p style="text-align:center">
                (* indicates corresponding author, + indicates equal contribution)
              </p>           

        
            </td>
          </tr>
        </tbody></table>







<div class="paper">


<ol reversed>
    <li><papertitle> LLDiffusion: Learning Degradation Representations in Diffusion Models for Low-Light Image Enhancement</papertitle>,
          <br>T. Wang, K. Zhang, Y. Zhang, W. Luo, B. Stenger, T. Lu, TK. Kim, W. Liu,<br> 
          <i>Pattern Recognition (PR), 2025. </i>
          <br>
             [<a href="" target="_blank">PDF</a>]
            <p></p>
    </li>
  
    <li><papertitle> LLFA: Fusing Global Illumination and Local Priors for Low-Light Face Image Enhancement with Adaptor</papertitle>,
          <br>Z. Shao, T. Wang*, K. Zhang, H. Dan, T. Lu,<br> 
          <i>Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2025. </i>
          <br>
             [<a href="" target="_blank">PDF</a>]
            <p></p>
    </li>
  
  <li><papertitle>Segmentation Guided Sparse Transformer for Under-Display Camera Image Restoration</papertitle>,
          <br>J. Xue, T. Wang, P. Dai, K. Zhang,<br> 
          <i>Proc. of IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2025. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2403.05906" target="_blank">PDF</a>]
            <p></p>
    </li>
  
  <li><papertitle>Visual Style Prompt Learning Using Diffusion Models for Blind Face Restoration</papertitle>,
          <br>W. Lu, J. Wang, T. Wang, K. Zhang, X. Jiang, H. Zhao,<br> 
          <i>Pattern Recognition (PR), 2025. </i>
          <br>
             [<a href="https://www.sciencedirect.com/science/article/abs/pii/S003132032401063X?via%3Dihub" target="_blank">PDF</a>]
             [<a href="https://github.com/LonglongaaaGo/VSPBFR">Code</a>]
            <p></p>
    </li>
  
    <li><papertitle>Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing</papertitle>,
          <br>Z. Kong, W. Zhang, T. Wang, K. Zhang, Y. Li, X. Tang, W. Luo,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2024. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2401.01102" target="_blank">PDF</a>]
            <p></p>
            </li>
  
    <li><papertitle>Blind Face Video Restoration with Temporal Consistent Generative Prior and Degradation-Aware Prompt</papertitle>,
          <br>J. Tan, H. Park, Y. Zhang, T. Wang, K. Zhang, X. Kong, P. Dai, Z. Liu, W. Luo,<br> 
          <i>Proc. of ACM International Conference on Multimedia (ACM MM), 2024. </i>
          <br>
            [<a href="https://openreview.net/pdf?id=qaIS3nvAem" target="_blank">PDF</a>]
            <p></p>
            </li>
  
    <li><papertitle>CorrAdaptor: Adaptive Local Context Learning for Correspondence Pruning</papertitle>,
          <br>W. Zhu, Y. Liu, Y. He, T. Liao, K. Zheng, X. Xu, T. Wang*, T. Lu,<br> 
          <i>Proc. of European Conference on Artificial Intelligence (ECAI), 2024. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2408.08134" target="_blank">PDF</a>]
             [<a href="https://github.com/TaoWangzj/CorrAdaptor">Code</a>]
            <p></p>
            </li>

    <li><papertitle>Omg: Occlusion-friendly Personalized Multi-concept Generation in Diffusion Models</papertitle>,
          <br>Z. Kong, Y. Zhang, T. Yang, T. Wang, K. Zhang, B. Wu, G. Chen, W. Liu,  W. Luo,<br> 
          <i>Proc. of European Conference on Computer Vision (ECCV), 2024. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2403.10983" target="_blank">PDF</a>]
             [<a href="https://github.com/kongzhecn/OMG">Code</a>]
            <p></p>
            </li>
  
       <li><papertitle>Towards Real-World Blind Face Restoration with Generative Diffusion Prior</papertitle>,
          <br> X. Chen, J. Tan, T. Wang, K. Zhang, W. Luo, X. Cao,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2024. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2312.15736.pdf" target="_blank">PDF</a>]
             [<a href="https://github.com/chenxx89/BFRffusion">Code</a>]
            <p></p>
            </li>
    <li><papertitle>Gridformer: Residual Dense Transformer with Grid Structure for Image Restoration in Adverse Weather Conditions</papertitle>,
          <br>T. Wang, K. Zhang, Z. Shao, W. Luo, B. Stenger, T. Lu, TK. Kim, W. Liu, H. Li,<br> 
          <i>International Journal of Computer Vision (IJCV), 2024. </i>
          <br>
             [<a href="https://arxiv.org/abs/2305.17863" target="_blank">PDF</a>]
             <a href="https://github.com/TaoWangzj/GridFormer">Code</a>]
            <p></p>
            </li>
  
    <li><papertitle>VSFormer: Visual-Spatial Fusion Transformer for Correspondence Pruning</papertitle>,
          <br>T. Liao, X. Zhang, L. Zhao, T. Wang, G. Xiao,<br> 
          <i>Proc. of the Association for the Advancement of Artificial Intelligence (AAAI), 2024. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2312.08774.pdf" target="_blank">PDF</a>]
             [<a href="https://github.com/sugar-fly/VSFormer">Code</a>]
            <p></p>
            </li>
  
    <li><papertitle>Blind Face Restoration for Under-Display Camera via Dictionary Guided Transformer</papertitle>,
          <br>J. Tan, X. Chen, T. Wang, K. Zhang, W. Luo, X. Cao,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2023. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2308.10196.pdf" target="_blank">PDF</a>]
            <p></p>
            </li>
  
    <li><papertitle>Punctuation-level Attack: Single-shot and Single Punctuation Can Fool Text Models</papertitle>,
          <br>W. Wang, C. Du, T. Wang, K. Zhang, W. Luo, L. Ma, W. Liu, X. Cao,<br> 
          <i>Proc. of Neural Information Processing Systems (NeurIPS), 2023. </i>
          <br>
             [<a href="https://openreview.net/pdf?id=ir6WWkFR80" target="_blank">PDF</a>]
            <p></p>
            </li>
   <li><papertitle>MC-Blur: A Comprehensive Benchmark for Image Deblurring</papertitle>,
          <br>K. Zhang, T. Wang, W. Luo, B. Chen, W. Ren, B. Stenger, W. Liu, H. Li, M.H. Yang,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2023. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2112.00234.pdf" target="_blank">PDF</a>]
             [<a href="https://github.com/HDCVLab/MC-Blur-Dataset">Code</a>]
            <p></p>
            </li>
    <li><papertitle>Restoring Vision in Hazy Weather with Hierarchical Contrastive Learning</papertitle>,
          <br>T. Wang, G. Tao, W. Lu, K. Zhang, W. Luo, X. Zhang, T. Lu,<br> 
          <i>Pattern Recognition (PR), 2023. </i>
          <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S0031320323006544" target="_blank">PDF</a>]
            <p></p>
          </li>
  
    <li><papertitle>Graph Propagation Transformer for Graph Representation Learning</papertitle>,
          <br>Z. Chen, H. Tan, T. Wang, T. Shen, T. Lu, Q. Peng, C. Cheng, Y. Qi,<br> 
          <i>Proc. of International Joint Conference on Artificial Intelligence (IJCAI), China, 2023. </i>
          <br>
             [<a href="https://arxiv.org/pdf/2305.11424.pdf" target="_blank">PDF</a>]
             [<a href="https://github.com/czczup/GPTrans">Code</a>]
            <p></p>
            </li>
  
   <li><papertitle>Multi-prior Driven Network for RGB-D Salient Object Detection</papertitle>,
          <br>X. Zhang, Y. Xu, T. Wang, T. Liao,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2023.</i>
          <br>
            [<a href="https://ieeexplore.ieee.org/document/10103917" target="_blank">PDF</a>]
            <p></p>
            </li>
  
  <li><papertitle>Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method</papertitle>,
    <br>T. Wang, K. Zhang, T. Shen, W. Luo, B. Stenger, T. Lu,<br>
    <i>Proc. of the Association for the Advancement of Artificial Intelligence (AAAI), USA, 2023. (<strong><font color="red">ORAL</font></strong>)</i>
    <br>
    [<a href="https://arxiv.org/pdf/2212.11548.pdf">PDF</a>]
    [<a href="https://github.com/TaoWangzj/LLFormer">Code</a>]
    [<a href="https://taowangzj.github.io/projects/LLFormer/">Project</a>]
    <p></p></li>  
  
<li><papertitle>Dynamic Feature Learning for COVID-19 Segmentation and Classification</papertitle>,
      <br>X. Zhang, R. Jiang, P. Huang, T. Wang, M. Hu, AF. Scarsbrook, AF. Frangi,<br> 
      <i>Computers in Biology and Medicine (CBM), 2022.</i>
      <br>
        [<a href="https://www.sciencedirect.com/science/article/pii/S0010482522008447" target="_blank">PDF</a>]
        <p></p>
        </li>

<li><papertitle>Uncertainty-Based Network for Few-Shot Image Classification</papertitle>,
  <br>M. Yuan, Q. Xu, C. Cai, Y. Zheng, T. Wang, T. Lu, W. Li,<br> 
  <i>Proc. of IEEE International Conference on Multimedia and Expo (ICME), 2022. (<strong><font color="red">ORAL</font></strong>)</i>
  <br>
    [<a href="https://ieeexplore.ieee.org/abstract/document/9859887" target="_blank">PDF</a>]
    <p></p>
    </li>

<li><papertitle>Haze Concentration Adaptive Network for Image Dehazing</papertitle>,
        <br>T. Wang, L. Zhao, P. Huang, X. Zhang, J. Xu,<br> 
        <i>Neurocomputing (Neuro), 2021.</i>
        <br>
          [<a href="https://www.sciencedirect.com/science/article/pii/S0925231221000631" target="_blank">PDF</a>]
          <p></p>
          </li>

  <li><papertitle>Video Deblurring via Spatiotemporal Pyramid Network and Adversarial Gradient Prior</papertitle>,
            <br>T. Wang, X. Zhang, R. Jiang, L. Zhao, H. Chen, W. Luo,<br>
            <i>Computer Vision and Image Understanding (CVIU), 2021.</i>
            <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S1077314220301545" target="_blank">PDF</a>]
            <p></p></li> 
  

  <li><papertitle>Single Image Haze Removal Based on a Simple Additive Model with Haze Smoothness Prior</papertitle>,
          <br>X. Zhang, T. Wang, G. Tang, L. Zhao, Y. Xu, S. Maybank,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2021.</i>
          <br>
            [<a href="https://ieeexplore.ieee.org/abstract/document/9543653" target="_blank">PDF</a>]
            <p></p>
            </li>


  <li><papertitle>Structured Dictionary Learning with Block Diagonal Regularization for Image Classification</papertitle>,
              <br>M. Xu, R. Jiang, T. Wang, D. Wang, X. Lu,<br> 
              <i>Proc. of IEEE International Conference on Big Data (Big Data), 2020.</i>
              <br>
                [<a href="https://ieeexplore.ieee.org/abstract/document/9378209" target="_blank">PDF</a>]
                <p></p>
                </li>
  
  <li><papertitle>Single Image Dehazing via Dual-Path Recurrent Network</papertitle>,
                  <br>X. Zhang, R. Jiang, T. Wang and W. Luo,<br>
                  <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
                  <br>
                  [<a href="https://ieeexplore.ieee.org/document/9435998" target="_blank">PDF</a>]
                  <p></p></li>

  <li><papertitle>Advances in Deep Learning Methods for Visual Tracking: Literature Review and Fundamentals</papertitle>,
                  <br>X. Zhang, R. Jiang, C. Fan, T. Tong, T. Wang, P. Huang,<br> 
                  <i>International Journal of Automation and Computing (IJAC), 2021.</i>
                  <br>
                    [<a href="https://link.springer.com/article/10.1007/s11633-020-1274-8" target="_blank">PDF</a>]
                    <p></p>
                    </li>

  <li><papertitle>Hierarchical Feature Fusion with Mixed Convolution Attention for Single Image Dehazing</papertitle>,
          <br>X. Zhang, J. Wang, T. Wang, R. Jiang,<br> 
          <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2021. (<strong><font color="red">ESI Highly Cited Paper</font></strong>)</i>
          <br>
            [<a href="https://ieeexplore.ieee.org/abstract/document/9381290/" target="_blank">PDF</a>]
            <p></p>
            </li>

  
  <li><papertitle>Attention-based Interpolation Network for Video Deblurring</papertitle>,
          <br>X. Zhang, R. Jiang, T. Wang, P. Huang, L. Zhao,<br> 
          <i>Neurocomputing (Neuro), 2021.</i>
          <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S092523122031362X" target="_blank">PDF</a>]
            <p></p>
            </li>   
  

        
  <li><papertitle>Self-filtering Image Dehazing with Self-supporting Module</papertitle>,
          <br>P. Huang, L. Zhao, R. Jiang, T. Wang, X. Zhang,<br> 
          <i>Neurocomputing (Neuro), 2021.</i>
          <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S0925231220318324" target="_blank">PDF</a>]
            <p></p>
            </li>    
        
  <li><papertitle>Robust Feature Learning for Adversarial Defense via Hierarchical Feature Alignment</papertitle>,
          <br>X. Zhang, J. Wang, T. Wang, R. Jiang, J. Xu, L. Zhao,<br> 
          <i>Information Sciences (IS), 2021.</i>
          <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S0020025520312081" target="_blank">PDF</a>]
            <p></p>
            </li>    
  
  
  <li><papertitle>Multi-level Fusion and Attention-guided CNN for Image Dehazing</papertitle>,
              <br>X. Zhang, T. Wang*, W. Luo, P. Huang,<br>
              <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2021. (<strong><font color="red">ESI Highly Cited Paper</font></strong>)</i>
              <br>
              [<a href="https://ieeexplore.ieee.org/abstract/document/9302656/" target="_blank">PDF</a>]
              <p></p></li>  
          
  <li><papertitle>Recursive Neural Netowrk for Video deblurring</papertitle>,
      <br>X. Zhang, R. Jiang, T. Wang, J. Wang,<br> 
      <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2020. (<strong><font color="red">ESI Highly Cited Paper</font></strong>)</i>
      <br>
        [<a href="https://ieeexplore.ieee.org/abstract/document/9247314" target="_blank">PDF</a>]
        <p></p>
        </li>

  <li><papertitle>Pyramid Channel-based Feature Attention Network for Image Dehazing</papertitle>,
    <br>X. Zhang, T. Wang, J. Wang, G. Tang, L. Zhao,<br> 
    <i>Computer Vision and Image Understanding (CVIU), 2020. (<strong><font color="red">ESI Highly Cited Paper</font></strong>)</i>
    <br>
      [<a href="https://www.sciencedirect.com/science/article/pii/S1077314220300709" target="_blank">PDF</a>]
      [<a href="https://github.com/TaoWangzj/PCFAN" target="_blank">Code</a>] 
      <p></p>
      </li>
  

     <br>


                              <div class="section">
                               <h2>Tech Report</h2>
                              <div class="research">
                                
                                
                                <papertitle>A Survey of Deep Face Restoration: Denoise, Super-Resolution, Deblur, Artifact Removal</papertitle>,
                                <br>T. Wang, K. Zhang, X. Chen, W. Luo, J. Deng, T. Lu, X. Cao, W. Liu, H. Li, S. Zafeiriou,<br>
                                <i>arXiv:2211.02831, 2022.</i>	
                                <br>
                                [<a href="https://arxiv.org/abs/2211.02831">arXiv</a>]
                                [<a href="https://github.com/TaoWangzj/Awesome-Face-Restoration">Project</a>]
                                <p></p>

                               
                            
                               
                                </div>

                                <br>


                                
          </ol>


          <br><br>





      </td>
    </tr>
  </table>
</body>

</html>
