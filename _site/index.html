<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Homepage - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Homepage">
<meta property="og:title" content="Homepage">


  <link rel="canonical" href="http://localhost:4000/">
  <meta property="og:url" content="http://localhost:4000/">



  <meta property="og:description" content="The homepage of Tao Wang">









<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#research">Research</a></li>
          
            <li class="masthead__menu-item"><a href="/#-news">News</a></li>
          
            <li class="masthead__menu-item"><a href="/#projects">Projects</a></li>
          
            <li class="masthead__menu-item"><a href="/#services">Services</a></li>
          
            <li class="masthead__menu-item"><a href="/publications/">Publications</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/taowang.jpg" class="author__avatar" alt="Tao Wang">
  </div>

  <div class="author__content">
    <h3 class="author__name">Tao Wang</h3>
    <p class="author__bio">Post-doctoral Fellow, HKUST</p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">The homepage of Tao Wang</div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Shanghai, China</li>
      
      
      
      
        <li><a href="mailto:taowangzj@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=TsDufoMAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:taowangzj@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.com/citations?user=TsDufoMAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<p><span class="anchor" id="about-me"></span></p>

<p>I am currently a  Post-doctoral Fellow in the <a href="https://c4g-hkust.github.io/">C4G</a> at Hong Kong University of Science and Technology (HKUST), working on low-level vision and multimodal generation. Before that, I received the Ph.D. degree from the School of Computer Science, Nanjing University (NJU), 2025, under the supervision of Prof. <a href="https://cs.nju.edu.cn/lutong/">Tong lu</a>. From September 2024 to March 2025, I worked as an academic intern at VIVO (Shanghai). I have published over 40+ peer-reviewed papers in top-tier journals and conferences, like IJCV, TIP, ICCV, ECCV, NeurIPS, SIGGRAPH, AAAI, IJCAI, ACM MM, etc. I am a reviewer for TPAMI, TIP, CVPR, ICCV, ECCV, NeurIPS, SIGGRAPH, ICLR, AAAI, IJCAI, etc.</p>

<p>Here is my <a href="files/Taowang_cv.pdf" target="_blank">[CV]</a>, and you can contact me by E-mail: <a href="mailto:taowangzj@gmail.com">taowangzj@gmail.com</a>.</p>

<p><span class="anchor" id="research"></span></p>
<h1 id="research">Research</h1>
<p>I am interested in several topics in computer vision and machine learning. Specifically, my research focuses on creative AI, such as image/video enhancement and synthesis, AI generated content (AIGC).</p>

<h1 id="-news">🔥 News</h1>
<ul>
  <li><em>2025.06</em>: 🎉 Updating new homepage.</li>
  <li><em>2025.06</em>: 🎉 Two papers were accepted by ICCV 2025 (MOERL and MaterialMVP).</li>
  <li><em>2025.05</em>:    Successfully defended PhD dissertation.</li>
  <li><em>2025.04</em>: 🎉 One paper was accepted by SIGGRAPH 2025 (video super-resolution).</li>
  <li><em>2025.03</em>: 🎉 One paper was accepted by PR (low-light enhancement).</li>
  <li><em>2024.12</em>: 🎉 Two papers were accepted by ICASSP 2025 (face enhancement, UDC image restoration).</li>
  <li><em>2024.11</em>: 🎉 BYD scholarship of Nanjing University.</li>
  <li><em>2024.08</em>: 🎉 One paper was accepted by TCSVT (face Anti-spoofing).</li>
  <li><em>2024/07</em>: 🎉 One paper was accepted by ACM MM 2024 (video face restoration).</li>
  <li><em>2024/07</em>: 🎉 One paper was accepted by ECAI 2024 (correspondence pruning).</li>
  <li><em>2024/07</em>: 🎉 One paper was accepted by ECCV 2024 (personalized text-to-image generation).</li>
  <li><em>2024/03</em>: 🎉 One paper was accepted by TCSVT (blind face restoration).</li>
  <li><em>2024/03</em>: 🎉 One paper was accepted by IJCV (adverse weather restoration).</li>
  <li><em>2023/12</em>: 🎉 One paper was accepted by AAAI 2024 (correspondence pruning).</li>
  <li><em>2023/11</em>: 🎉 One paper was accepted by TCSVT (under-display camera face image restoration).</li>
  <li><em>2023/11</em>: Sun-Xiangzhen scholarship of Nanjing University.</li>
  <li><em>2023/09</em>: 🎉 One paper was accepted by NeurIPS 2023 (punctuation-level attack for text models).</li>
  <li><em>2023/09</em>: 🎉 One paper was accepted by TCSVT (a comprehensive benchmark for image deblurring).</li>
  <li><em>2023/09</em>: 🎉 One paper was accepted by PR (image dehazing).</li>
  <li><em>2023/04</em>: 🎉 One paper was accepted by IJCAI 2023 (graph representation learning).</li>
  <li><em>2023/04</em>: 🎉 One paper was accepted by TCSVT (rgb-d salient object detection).</li>
  <li><em>2023/01</em>: 🎉 One paper was selected for an ORAL presentation at AAAI 2023 (UHD low-light enhancement).</li>
  <li><em>2022/11</em>: 🎉 One paper was accepted by AAAI 2023 (UHD low-light enhancement).</li>
  <li><em>2022/11</em>: One paper was online in Arxiv (face restoration survey), see the <a href="https://www.51cto.com/article/740298.html">news</a>.</li>
</ul>

<p><span class="anchor" id="projects"></span></p>
<h1 id="projects">Projects</h1>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge"> </div><img src="images/MOERL.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="">MOERL: When Mixture-of-Experts Meet Reinforcement Learning for Adverse Weather Image Restoration</a></p>

    <p><strong>T. Wang</strong>, P. Xia, B. Li, P. Jiang, Z. Kong, K. Zhang, T. Lu, W. Luo</p>

    <p>Proc. of International Conference on Computer Vision (ICCV), 2025.</p>

    <p><a href=""><strong>PDF</strong></a> <a href=""><strong>Code</strong></a></p>
    <ul>
      <li>A general backbone with RL for image restoration in adverse weather conditions.</li>
    </ul>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge"> </div><img src="images/GridFormer2.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/abs/2305.17863">GridFormer: Residual Dense Transformer with Grid Structure for Image Restoration in Adverse Weather Conditions</a></p>

    <p><strong>T. Wang</strong>, K. Zhang, Z. Shao, W. Luo, B. Stenger, T. Lu, TK. Kim, W. Liu, H. Li</p>

    <p>International Journal of Computer Vision (IJCV), 2024.</p>

    <p><a href="https://link.springer.com/article/10.1007/s11263-024-02056-0"><strong>PDF</strong></a> <a href="https://github.com/TaoWangzj/GridFormer"><strong>Code</strong></a></p>
    <ul>
      <li>A general Transformer backbone for image restoration in adverse weather conditions.</li>
    </ul>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge"> </div><img src="images/LLFormer2.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://arxiv.org/pdf/2212.11548.pdf">Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method</a></p>

    <p><strong>T. Wang</strong>, K. Zhang, T. Shen, W. Luo, B. Stenger, T. Lu</p>

    <p>Proc. of the Association for the Advancement of Artificial Intelligence (AAAI), 2023.</p>

    <p><a href="https://arxiv.org/pdf/2212.11548.pdf"><strong>PDF</strong></a> <a href="https://github.com/TaoWangzj/LLFormer"><strong>Code</strong></a></p>
    <ul>
      <li>The first work proposing the UHD-LLIE problem and addressing it with transformer.</li>
    </ul>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge"> </div><img src="images/LLDiffusion.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325002882">LLDiffusion: Learning Degradation Representations in Diffusion Models for Low-Light Image Enhancement</a></p>

    <p><strong>T. Wang</strong>, K. Zhang, Y. Zhang, W. Luo, B. Stenger, T. Lu, TK. Kim, W. Liu</p>

    <p>Pattern Recognition (PR), 2025.</p>

    <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320325002882"><strong>PDF</strong></a> <a href="https://github.com/TaoWangzj/LLDiffusion"><strong>Code</strong></a></p>
    <ul>
      <li>Image enhancement with diffusion model and degradation learning.</li>
    </ul>
  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge"> </div><img src="images/HCD.jpg" alt="sym" width="100%" /></div></div>
<div class="paper-box-text">

    <p><a href="https://www.sciencedirect.com/science/article/pii/S0031320323006544">Restoring Vision in Hazy Weather with Hierarchical Contrastive Learning</a></p>

    <p><strong>T. Wang</strong>, G. Tao, W. Lu, K. Zhang, W. Luo, X. Zhang, T. Lu</p>

    <p>Pattern Recognition (PR), 2023.</p>

    <p><a href="https://www.sciencedirect.com/science/article/pii/S0031320323006544"><strong>PDF</strong></a></p>
    <ul>
      <li>A framework using contrastive learning to produce visually pleasing images.</li>
    </ul>
  </div>
</div>

<p><span class="anchor" id="services"></span></p>
<h1 id="professional-activities">Professional Activities</h1>

<p>Conference Reviewer: CVPR, ECCV, ICCV, NeurIPS, ICLR, SIGGRAPH, AAAI, IJCAI, ACM MM, etc.</p>

<p>Journal Reviewer: TPAMI, TIP, TCSVT, CVIU, TII, TMM, ITS, NN, etc.</p>

<p><span class="anchor" id="Visitor"></span></p>
<h1 id="️-visitor-">⭐️ Visitor <img src="https://visitor-badge.laobi.icu/badge?page_id=taowangzj.github.io" alt="Visitor Count" /></h1>

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=HpDM8e07AdKUqxj7S-j1Bl0FyDqsg4moaSLvltwybqo&amp;cl=ffffff&amp;w=a"></script>


          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/TaoWangzj/taowangzj.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


  </body>
</html>
